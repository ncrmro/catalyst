name: "Copilot Setup Steps"

# Automatically run the setup steps when they are changed to allow for easy validation, and
# allow manual testing through the repository's "Actions" tab
#
# This workflow sets up the environment for GitHub Copilot agents to work on the catalyst repository.
# It provides:
# - PostgreSQL database for integration tests
# - Kind Kubernetes cluster with ingress controller
# - Environment CRD and test resources
# - npm dependencies and database migrations
#
# Supported test suites:
# - Unit tests: npm run test:unit
# - Component tests: npm run test:components  
# - Integration tests: npm run test:integration (133/135 tests pass)
# - E2E tests: npm run test:e2e
#
# Known limitations:
# - k8s-pull-request-pod-docker-build test requires additional RBAC setup for Docker buildx
#   within pods. This test is skipped in copilot environments.
on:
  workflow_dispatch:
  push:
    paths:
      - .github/workflows/copilot-setup-steps.yml
  pull_request:
    paths:
      - .github/workflows/copilot-setup-steps.yml

jobs:
  # The job MUST be called `copilot-setup-steps` or it will not be picked up by Copilot.
  copilot-setup-steps:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:17-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: catalyst
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    # Set the permissions to the lowest permissions possible needed for your steps.
    # Copilot will be given its own token for its operations.
    permissions:
      # If you want to clone the repository as part of your setup steps, for example to install dependencies, you'll need the `contents: read` permission. If you don't clone the repository in your setup steps, Copilot will do this for you automatically after the steps complete.
      contents: read

    # You can define any steps you want, and they will run before the agent starts.
    # If you do not check out your code, Copilot will do this for you.
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'
          cache-dependency-path: './web/package-lock.json'

      - name: Install Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.24'

      - name: Get Playwright version
        id: playwright-version
        run: echo "version=$(node -p "require('./web/package.json').devDependencies['@playwright/test'].replace('^', '')")" >> $GITHUB_OUTPUT

      - name: Cache playwright binaries
        uses: actions/cache@v4
        id: playwright-cache
        with:
          path: |
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ steps.playwright-version.outputs.version }}

      # Copliot setup steps don't respect changing the directory between steps
      - run: |
          cd ./web
          cp .env.example .env
          npm ci
          npm run db:migrate
          npm run seed

      # Install Playwright browsers after npm ci to ensure dependencies are available
      - name: Install Playwright browsers
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: |
          cd ./web
          npx playwright install --with-deps --no-shell

      - run: env

      - name: Create Kind cluster with ingress port mapping
        run: |
          # Create Kind cluster with port mappings for ingress controller
          # Maps container port 80 to host port 8080 for localhost access
          cat <<EOF | kind create cluster --name preview-cluster --config=-
          kind: Cluster
          apiVersion: kind.x-k8s.io/v1alpha4
          nodes:
            - role: control-plane
              kubeadmConfigPatches:
                - |
                  kind: InitConfiguration
                  nodeRegistration:
                    kubeletExtraArgs:
                      node-labels: "ingress-ready=true"
              extraPortMappings:
                - containerPort: 80
                  hostPort: 8080
                  protocol: TCP
          EOF
          echo "Kind cluster created with ingress port mapping (80 -> 8080)"

      - name: Verify Kind Access
        run: kubectl get all

      - name: Install NGINX Ingress Controller
        run: |
          # Install NGINX Ingress Controller for Kind
          kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml
          # Use rollout status which properly waits for pods to be ready
          kubectl rollout status deployment/ingress-nginx-controller -n ingress-nginx --timeout=120s
          echo "NGINX Ingress Controller installed and ready"

      - name: Install Environment CRD
        run: |
          kubectl apply -f ./operator/config/crd/bases/catalyst.catalyst.dev_environments.yaml
          echo "Environment CRD installed"

      - name: Deploy test application
        run: |
          # Deploy a lightweight nginx server as test application
          kubectl create deployment ci-test-app --image=nginx:alpine -n default
          kubectl expose deployment ci-test-app --port=80 --target-port=80 -n default
          kubectl wait --for=condition=available deployment/ci-test-app -n default --timeout=60s
          echo "Test application deployed"

      - name: Create test ingress
        run: |
          # Create ingress for test application with hostname-based routing
          cat <<EOF | kubectl apply -f -
          apiVersion: networking.k8s.io/v1
          kind: Ingress
          metadata:
            name: ci-test-env-ingress
            namespace: default
          spec:
            ingressClassName: nginx
            rules:
              - host: test-project-ci-test-env.localhost
                http:
                  paths:
                    - path: /
                      pathType: Prefix
                      backend:
                        service:
                          name: ci-test-app
                          port:
                            number: 80
          EOF
          # Wait for ingress to be processed
          sleep 5
          kubectl get ingress -n default
          echo "Test ingress created"

      - name: Create test Environment CR
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: catalyst.catalyst.dev/v1alpha1
          kind: Environment
          metadata:
            name: ci-test-env
            namespace: default
          spec:
            projectRef:
              name: test-project
            type: development
            deploymentMode: development
            source:
              commitSha: abc123
              branch: main
          EOF
          echo "Test Environment CR created"

      - name: Patch Environment status to Ready
        run: |
          kubectl patch environment ci-test-env -n default \
            --type=merge --subresource=status \
            -p '{"status":{"phase":"Ready","url":"http://test-project-ci-test-env.localhost:8080/"}}'
          echo "Environment status patched to Ready"

      - name: Add Kind kubeconfig to .env
        run: |
          # Get kubeconfig from kind as YAML
          KIND_KUBECONFIG=$(kind get kubeconfig --name preview-cluster)
          
          # Convert YAML to JSON and base64 encode
          KUBECONFIG_JSON_B64=$(echo "$KIND_KUBECONFIG" | yq eval -o json | base64 -w 0)
          
          # Add KUBECONFIG_PRIMARY to .env file
          cd ./web
          echo "KUBECONFIG_PRIMARY=$KUBECONFIG_JSON_B64" >> .env
          echo "LOCAL_PREVIEW_ROUTING=true" >> .env
          echo "INGRESS_PORT=8080" >> .env

      - name: Validate Kubernetes Integration
        run: |
          cd ./web
          # Run a basic integration test to verify Kubernetes access
          npm run test:integration -- __tests__/integration/k8s-namespaces.test.ts
          echo "âœ“ Kubernetes integration tests are working"

      # TODO: Something about the nix flake has broken this workflow.
      # We have reverted to the standard setup above and added Go dependencies.
      # The broken Nix-based setup is preserved below for reference/debugging.
      #
      # - name: Install Nix
      #   uses: cachix/install-nix-action@v31
      #   with:
      #     nix_path: nixpkgs=channel:nixos-unstable
      #
      # - uses: nicknovitski/nix-develop@v1
      #
      # - name: Print Tool Versions
      #   run: |
      #     echo "Node version: $(node --version)"
      #     echo "NPM version: $(npm --version)"
      #     echo "Playwright version: $(npx playwright --version)"
      #
      # - name: Setup Web Environment
      #   run: |
      #     cd web
      #     cp .env.example .env
      #     npm ci
      #     npm run db:migrate
      #
      # - run: env
      #
      # - name: Create Kind cluster
      #   run: |
      #     kind create cluster --name preview-cluster --wait 60s
      #
      # - name: Verify Kind Access
      #   run: |
      #     kubectl get all
      #
      # - name: Add Kind kubeconfig to .env
      #   run: |
      #     # Get kubeconfig from kind as YAML
      #     KIND_KUBECONFIG=$(kind get kubeconfig --name preview-cluster)
      #     
      #     # Convert YAML to JSON and base64 encode
      #     KUBECONFIG_JSON_B64=$(echo "$KIND_KUBECONFIG" | yq eval -o json | base64 -w 0)
      #     
      #     # Add KUBECONFIG_PRIMARY to .env file
      #     cd ./web
      #     echo "KUBECONFIG_PRIMARY=$KUBECONFIG_JSON_B64" >> .env